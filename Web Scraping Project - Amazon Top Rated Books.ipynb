{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93e0f09",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "## Using requests, BeautifulSoup and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a69d6",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/6zM7JBq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387caf51",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It’s a useful technique for creating datasets for research and learning. There are many example where by using we can create dataset and automate the process to get the data e.g. Laptop’s price scraper from various website, top movie rating scraping, Mutual fund NAV scrapping which may further be use to create a data set for EDA and Machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d20b9",
   "metadata": {},
   "source": [
    "We are going to Scrap a list of top seller books and details about the book for each category from Amazon best selling website. Amazon is an multinational technology company that focuses on e-commerce , cloud computing , digital streaming and AI.\n",
    "\n",
    "We will use this https://www.amazon.in/gp/bestsellers/books/ page to retrieve the information using web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abb239",
   "metadata": {},
   "source": [
    "### The steps we’ll follow:\n",
    "* We’re going to scrape https://www.amazon.in/gp/bestsellers/books/\n",
    "* We’ll get a list of topics.\n",
    "* For each topic, we’ll get topic title, topic page URL\n",
    "* For each topic, we’ll get the top 50 books in the topic from the topic page\n",
    "* For each book, we’ll grab the book name, book URL, author name, book price, star rating and No of customer rated as rating.\n",
    "* Save the information data to CSV file Using Pandas library\n",
    "* By the end of the project we will be able to create a CSV file with the following info:\n",
    "#### title, url ,book_name ,author name ,book price ,star rating , rating, book_url."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fd411",
   "metadata": {},
   "source": [
    "### Install and Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3e00f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d1012",
   "metadata": {},
   "source": [
    "### Downloading a web page using requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c80558",
   "metadata": {},
   "source": [
    "When you access a URL like using a web browser, it downloads the contents of the web page the URL points to and displays the output on the screen. Before we can extract information from a web page, we need to download the page using Python.\n",
    "\n",
    "We’ll use a library called requests to download web pages from the internet. We can download a web page using the requests.get function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "340c928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url = 'https://www.amazon.in/gp/bestsellers/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb81a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f6488",
   "metadata": {},
   "source": [
    "requests.getfunction returns a response object with the page contents and some information indicating whether the request was successful, using a status code.response.status_code will provide you the code whether the request was successful or not. If the status.code lies between 200 to 209 then the request was successful otherwise it was not successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "889d4195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c018b",
   "metadata": {},
   "source": [
    "The contents of the web page can be accessed using the .text property of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "928471ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327511"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents = response.text\n",
    "len(page_contents)    #The `len` fucnction tells us the length of the response object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a51659",
   "metadata": {},
   "source": [
    "### Inspect HTML of the web page\n",
    "We can view the source code of the webpage by doing right-clicking anywhere on the web page and selecting ‘Inspect’ option. It opens the “Developer Tools” pane, where we can see the source code as a tree. We can expand and collapse various nodes and find the source code for a specific portion of the page.\n",
    "\n",
    "Here’s how our web page look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b2dcd",
   "metadata": {},
   "source": [
    "![](https://imgur.com/tXEOKKj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017eb6e",
   "metadata": {},
   "source": [
    "As shown above ,We can find out ‘topic title’ are present in the “div” tag under class -”p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa7cfb",
   "metadata": {},
   "source": [
    "### Extracting information by parsing HTML source code using BeautifulSoup library\n",
    "To extract information from the HTML source code, we will use the Beautiful Soup library. Beautiful Soup will return an object containing several properties and methods to extract the information from HTML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8527945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66c3390b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005f213",
   "metadata": {},
   "source": [
    "Lets create the helper function and extract the topic title and topic URL’s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "218d1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response = requests.get(topic_url)\n",
    "    #Check successful Response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    #Parse using Beautiful Soup\n",
    "    topic_doc = BeautifulSoup(response.text,'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38c4f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page('https://www.amazon.in/gp/bestsellers/books')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c60e9",
   "metadata": {},
   "source": [
    "Lets find the Topic title, which is inside the div tag with class set to '_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e649979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_class = '_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8'\n",
    "topic_title_tags = doc.find_all('div',class_=sel_class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6e1b7a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_title_tags)  # this is the table length which contains topic title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab372c",
   "metadata": {},
   "source": [
    "The above topic title contains the 36 different categories of books , we will parse each category of book and get the top seller 50 books in each category.\n",
    "\n",
    "Lets create the helper function and extract the topic title and topic URL’s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71d2e2",
   "metadata": {},
   "source": [
    "Lets create the helper function\n",
    "#### Topic Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8985dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(topic_title_tags): # this function is created to get the topic title\n",
    "    topic = topic_title_tags.find('a').text\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed29a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_topic_titles(topic_title_tags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ec53f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action & Adventure'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13956d",
   "metadata": {},
   "source": [
    "#### Topic URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aea72e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(topic_title_tags): # this function is created to get the topic title url\n",
    "    base_url ='https://www.amazon.in/'\n",
    "    table_tag_href = base_url + topic_title_tags.find('a')['href']\n",
    "    return table_tag_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "47601037",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_topic_urls(topic_title_tags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27bd9d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amazon.in//gp/bestsellers/books/1318158031/ref=zg_bs_nav_books_1'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69c330",
   "metadata": {},
   "source": [
    "Now we got the 36 different URL’s for all the category. Lets parse each URL and get the Book Name, Book URL, Author Name, Price and Rating of the each book.\n",
    "\n",
    "Lets find the Book Name , which is inside the div tag with class set to zg-grid-general-faceout which is inside span tag and div tag,using the helper function get_books_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff98d17",
   "metadata": {},
   "source": [
    "#### Book Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c084b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_name(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    books_name = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            author_tag = books_tag[i].find('div',class_='zg-grid-general-faceout').find('span').find('div').text\n",
    "            books_name.append(author_tag)\n",
    "        except AttributeError:\n",
    "            books_name.append(None)\n",
    "    return books_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8fa9eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_name = get_books_name(get_topic_page(b)) # b contains the url for the  first topic \"action and adventure\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e49d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harry Potter and the Philosopher's Stone\",\n",
       " 'THE SILENT PATIENT [Paperback] Michaelides, Alex',\n",
       " 'THE LION INSIDE',\n",
       " 'The Housemaid : An addictive psychological thriller with mind-bending twists',\n",
       " 'Samsara: Enter the Valley of the Gods (\"India\\'s answer to Harry Potter\") | Mythological fiction novel']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_name[0:5] # Printing first 5 book name from action and adventure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53a473",
   "metadata": {},
   "source": [
    "#### Book URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f0f6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_books_url(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    base_url = 'https://www.amazon.in/'\n",
    "    books_url = []\n",
    "    for i in range(len( books_tag)):\n",
    "        url = base_url + books_tag[i].find('a')['href']\n",
    "        books_url.append(url)\n",
    "    return books_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea685878",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_url = get_books_url(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9be597ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in//Harry-Potter-Philosophers-Stone-Rowling-ebook/dp/B019PIOJYU/ref=zg_bs_g_1318158031_d_sccl_1/257-2841279-6502826?psc=1',\n",
       " 'https://www.amazon.in//Silent-Patient-Alex-Michaelides/dp/1409181634/ref=zg_bs_g_1318158031_d_sccl_2/257-2841279-6502826?psc=1',\n",
       " 'https://www.amazon.in//LION-INSIDE-Rachel-Bright/dp/1408349043/ref=zg_bs_g_1318158031_d_sccl_3/257-2841279-6502826?psc=1',\n",
       " 'https://www.amazon.in//Housemaid-addictive-psychological-thriller-mind-bending/dp/014346115X/ref=zg_bs_g_1318158031_d_sccl_4/257-2841279-6502826?psc=1',\n",
       " 'https://www.amazon.in//Samsara-Valley-Indias-answer-Potter/dp/0143458280/ref=zg_bs_g_1318158031_d_sccl_5/257-2841279-6502826?psc=1']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_url [:5] # printing first 5 URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d575aa1",
   "metadata": {},
   "source": [
    "#### Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cca65057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_name(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div', class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    author_name = []\n",
    "    \n",
    "    for i in range(len(books_tag)):\n",
    "        try:\n",
    "            author_tag = books_tag[i].find('div', class_='a-row a-size-small').text\n",
    "            author_name.append(author_tag)\n",
    "        except AttributeError:\n",
    "            author_name.append(None)\n",
    "        except Exception as e:\n",
    "            author_name.append(None)\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "    return author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "63850ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name = get_author_name(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad03b3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['J.K. Rowling',\n",
       " 'Alex Michaelides',\n",
       " 'Rachel Bright',\n",
       " 'Freida McFadden',\n",
       " 'Saksham Garg']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843728d6",
   "metadata": {},
   "source": [
    "#### Book Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "25e104b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_price(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    book_price = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            price_tag =books_tag[i].find('span',class_='p13n-sc-price').text\n",
    "            book_price.append(price_tag)\n",
    "        except AttributeError:\n",
    "            book_price.append(None)\n",
    "          \n",
    "    return book_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "66fca66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "book_price = get_book_price(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d96e2711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹313.95', '₹250.88', '₹254.00', '₹310.00', '₹165.00']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_price[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd8aee",
   "metadata": {},
   "source": [
    "#### Star Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "deaa9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_star_rating(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    star_rating = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            star_tag = books_tag[i].find('div',class_='a-icon-row').text[0:3]\n",
    "            star_rating.append(star_tag)\n",
    "        except AttributeError:\n",
    "            star_rating.append(None)\n",
    "    return star_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "199753bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_rating = get_star_rating(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ea62f438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.7', '4.6', '3.5', None, '4.5', '4.6', '4.8', '4.8', '4.6', '4.6', '4.6']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_rating[26:37]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446caee",
   "metadata": {},
   "source": [
    "#### Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "203df1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(topic_doc):\n",
    "    books_tag = topic_doc.find_all('div',class_=\"a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc\")\n",
    "    rating = []\n",
    "    for i in range(len( books_tag)):\n",
    "        try:\n",
    "            rating_tag= books_tag[i].find('div',class_='a-icon-row')('span')[1].text\n",
    "            rating.append(rating_tag)\n",
    "        except TypeError:\n",
    "            rating.append(None)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "da6ad15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = get_rating(get_topic_page(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "93441b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['68,429', '325,888', '8,486', '365,191', '1,665']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8cad3",
   "metadata": {},
   "source": [
    "### Let’s create a function to put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4af0674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic_list(main_url):\n",
    "    main_dict = {\n",
    "        'title': [],\n",
    "        'url': [],\n",
    "        'book_name': [],\n",
    "        'books_url': [],\n",
    "        'author_name': [],\n",
    "        'book_price': [],\n",
    "        'star_rating': [],\n",
    "        'rating': []\n",
    "    }\n",
    "    \n",
    "    doc = get_topic_page(main_url)     \n",
    "    sel_class = '_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8'\n",
    "    topic_title_tags = doc.find_all('div', class_=sel_class)\n",
    "    \n",
    "    for i in topic_title_tags[1:35]:\n",
    "        title = get_topic_titles(i)\n",
    "        url = get_topic_urls(i)\n",
    "        print(f\"Fetching details from URL: {url}\")  # Debugging URL\n",
    "        try:\n",
    "            topic_doc = get_topic_page(url)\n",
    "            books = get_books_name(topic_doc) or [None]\n",
    "            authors = get_author_name(topic_doc) or [None]\n",
    "            prices = get_book_price(topic_doc) or [None]\n",
    "            star_ratings = get_star_rating(topic_doc) or [None]\n",
    "            ratings = get_rating(topic_doc) or [None]\n",
    "            books_urls = get_books_url(topic_doc) or [None]\n",
    "            \n",
    "            # Repeat the topic title and URL for the number of books in the topic\n",
    "            main_dict['title'].extend([title] * len(books))\n",
    "            main_dict['url'].extend([url] * len(books))\n",
    "            \n",
    "            main_dict['book_name'].extend(books)\n",
    "            main_dict['author_name'].extend(authors)\n",
    "            main_dict['book_price'].extend(prices)\n",
    "            main_dict['star_rating'].extend(star_ratings)\n",
    "            main_dict['rating'].extend(ratings)\n",
    "            main_dict['books_url'].extend(books_urls)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching URL {url}: {e}\")\n",
    "            continue  # Skip to the next iteration\n",
    "\n",
    "    # Debugging: Check if all lists have the same length\n",
    "    for key, value in main_dict.items():\n",
    "        print(f\"Length of {key}: {len(value)}\")\n",
    "\n",
    "    # Creating the DataFrame\n",
    "    df = pd.DataFrame(main_dict)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "33a086b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318158031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318052031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318064031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318068031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/64619755031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318104031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318105031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318118031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318161031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/22960344031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149751031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1402038031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318128031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/23033693031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149418031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318164031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149493031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318143031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318144031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149542031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318157031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318298031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149549031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318176031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318185031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318188031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318168031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149807031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/4149708031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318203031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318216031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/1318224031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/64619754031\n",
      "Fetching details from URL: https://www.amazon.in//gp/bestsellers/books/15417300031\n",
      "Length of title: 1700\n",
      "Length of url: 1700\n",
      "Length of book_name: 1700\n",
      "Length of books_url: 1700\n",
      "Length of author_name: 1700\n",
      "Length of book_price: 1700\n",
      "Length of star_rating: 1700\n",
      "Length of rating: 1700\n"
     ]
    }
   ],
   "source": [
    "scrape_df= scrape_topic_list('https://www.amazon.in/gp/bestsellers/books/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8cd7dc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>book_name</th>\n",
       "      <th>books_url</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_price</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>https://www.amazon.in//Harry-Potter-Philosophe...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>₹313.95</td>\n",
       "      <td>4.7</td>\n",
       "      <td>68,429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>THE SILENT PATIENT [Paperback] Michaelides, Alex</td>\n",
       "      <td>https://www.amazon.in//Silent-Patient-Alex-Mic...</td>\n",
       "      <td>Alex Michaelides</td>\n",
       "      <td>₹250.88</td>\n",
       "      <td>4.5</td>\n",
       "      <td>325,888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>THE LION INSIDE</td>\n",
       "      <td>https://www.amazon.in//LION-INSIDE-Rachel-Brig...</td>\n",
       "      <td>Rachel Bright</td>\n",
       "      <td>₹254.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8,486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>The Housemaid : An addictive psychological thr...</td>\n",
       "      <td>https://www.amazon.in//Housemaid-addictive-psy...</td>\n",
       "      <td>Freida McFadden</td>\n",
       "      <td>₹310.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>365,191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/13...</td>\n",
       "      <td>Samsara: Enter the Valley of the Gods (\"India'...</td>\n",
       "      <td>https://www.amazon.in//Samsara-Valley-Indias-a...</td>\n",
       "      <td>Saksham Garg</td>\n",
       "      <td>₹165.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>Textbooks &amp; Study Guides</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/15...</td>\n",
       "      <td>Cursive Writing Books (Set of 5 Books) (Handwr...</td>\n",
       "      <td>https://www.amazon.in//Cursive-Writing-Books-S...</td>\n",
       "      <td>Maple Press</td>\n",
       "      <td>₹348.00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1,703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>Textbooks &amp; Study Guides</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/15...</td>\n",
       "      <td>VCP Early Learning Educational Chart Set for K...</td>\n",
       "      <td>https://www.amazon.in//Learning-Educational-LA...</td>\n",
       "      <td>Vidya Chitr Prakashan</td>\n",
       "      <td>₹199.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>Textbooks &amp; Study Guides</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/15...</td>\n",
       "      <td>World's Greatest Leaders: Biographies of Inspi...</td>\n",
       "      <td>https://www.amazon.in//Worlds-Greatest-Leaders...</td>\n",
       "      <td>Wonder House Books</td>\n",
       "      <td>₹109.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Textbooks &amp; Study Guides</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/15...</td>\n",
       "      <td>Princess Colouring Book (Giant Book Series): J...</td>\n",
       "      <td>https://www.amazon.in//Princess-Colouring-Book...</td>\n",
       "      <td>Wonder House Books</td>\n",
       "      <td>₹149.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2,480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Textbooks &amp; Study Guides</td>\n",
       "      <td>https://www.amazon.in//gp/bestsellers/books/15...</td>\n",
       "      <td>Metamorphosis Complete Edition [Franz Kafka Cl...</td>\n",
       "      <td>https://www.amazon.in//Metamorphosis-Franz-Kaf...</td>\n",
       "      <td>Franz Kafka</td>\n",
       "      <td>₹103.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13,062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0           Action & Adventure   \n",
       "1           Action & Adventure   \n",
       "2           Action & Adventure   \n",
       "3           Action & Adventure   \n",
       "4           Action & Adventure   \n",
       "...                        ...   \n",
       "1695  Textbooks & Study Guides   \n",
       "1696  Textbooks & Study Guides   \n",
       "1697  Textbooks & Study Guides   \n",
       "1698  Textbooks & Study Guides   \n",
       "1699  Textbooks & Study Guides   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "1     https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "2     https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "3     https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "4     https://www.amazon.in//gp/bestsellers/books/13...   \n",
       "...                                                 ...   \n",
       "1695  https://www.amazon.in//gp/bestsellers/books/15...   \n",
       "1696  https://www.amazon.in//gp/bestsellers/books/15...   \n",
       "1697  https://www.amazon.in//gp/bestsellers/books/15...   \n",
       "1698  https://www.amazon.in//gp/bestsellers/books/15...   \n",
       "1699  https://www.amazon.in//gp/bestsellers/books/15...   \n",
       "\n",
       "                                              book_name  \\\n",
       "0              Harry Potter and the Philosopher's Stone   \n",
       "1      THE SILENT PATIENT [Paperback] Michaelides, Alex   \n",
       "2                                       THE LION INSIDE   \n",
       "3     The Housemaid : An addictive psychological thr...   \n",
       "4     Samsara: Enter the Valley of the Gods (\"India'...   \n",
       "...                                                 ...   \n",
       "1695  Cursive Writing Books (Set of 5 Books) (Handwr...   \n",
       "1696  VCP Early Learning Educational Chart Set for K...   \n",
       "1697  World's Greatest Leaders: Biographies of Inspi...   \n",
       "1698  Princess Colouring Book (Giant Book Series): J...   \n",
       "1699  Metamorphosis Complete Edition [Franz Kafka Cl...   \n",
       "\n",
       "                                              books_url  \\\n",
       "0     https://www.amazon.in//Harry-Potter-Philosophe...   \n",
       "1     https://www.amazon.in//Silent-Patient-Alex-Mic...   \n",
       "2     https://www.amazon.in//LION-INSIDE-Rachel-Brig...   \n",
       "3     https://www.amazon.in//Housemaid-addictive-psy...   \n",
       "4     https://www.amazon.in//Samsara-Valley-Indias-a...   \n",
       "...                                                 ...   \n",
       "1695  https://www.amazon.in//Cursive-Writing-Books-S...   \n",
       "1696  https://www.amazon.in//Learning-Educational-LA...   \n",
       "1697  https://www.amazon.in//Worlds-Greatest-Leaders...   \n",
       "1698  https://www.amazon.in//Princess-Colouring-Book...   \n",
       "1699  https://www.amazon.in//Metamorphosis-Franz-Kaf...   \n",
       "\n",
       "                author_name book_price star_rating   rating  \n",
       "0              J.K. Rowling    ₹313.95         4.7   68,429  \n",
       "1          Alex Michaelides    ₹250.88         4.5  325,888  \n",
       "2             Rachel Bright    ₹254.00         4.7    8,486  \n",
       "3           Freida McFadden    ₹310.00         4.4  365,191  \n",
       "4              Saksham Garg    ₹165.00         4.3    1,665  \n",
       "...                     ...        ...         ...      ...  \n",
       "1695            Maple Press    ₹348.00         4.4    1,703  \n",
       "1696  Vidya Chitr Prakashan    ₹199.00         4.2      258  \n",
       "1697     Wonder House Books    ₹109.00         4.3    3,379  \n",
       "1698     Wonder House Books    ₹149.00         4.5    2,480  \n",
       "1699            Franz Kafka    ₹103.00         4.5   13,062  \n",
       "\n",
       "[1700 rows x 8 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e522f2",
   "metadata": {},
   "source": [
    "We have successfully extracted the information from all the webpages in the format of list of dictionaries. For easier understanding, we are converting the same into CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee8003",
   "metadata": {},
   "source": [
    "### Save the extracted information into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ab9e056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_df.to_csv('top_rated_books.csv',index = None)     #Converting the final Dataframe 'scrape_df' to a CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e988022",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* Install and import libraries\n",
    "* Download and Parse the Best seller HTML page source code using resquest and Beautifulsoup to get item categories topics URL.\n",
    "* Extract information from each page\n",
    "* Created Pandas DataFrame using a Function\n",
    "* Save the information data to CSV file Using Pandas library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
